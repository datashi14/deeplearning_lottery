# TicketSmith: ML Platform for Neural Pruning & Cost Optimization

**TicketSmith** is a production-style ML experimentation platform designed to operationalize the **Lottery Ticket Hypothesis (LTH)**. It enables teams to find the "Cost-Quality Sweet Spot" by identifying sparse subnetworks that maintain dense-model performance at a fraction of the compute cost.

---

## üöÄ The Mission: Slashing Generative AI Costs

Generative AI deployment is bottlenecked by **GPU costs**. As models scale, they become:

- **Expensive to infer**: High latency and dollar-cost per token/image.
- **Hard to deploy**: Massive memory footprints require high-end hardware.
- **Risky to operate**: Scaling to millions of users scales costs linearly.

**TicketSmith** solves this by creating a reusable "Experiment Factory" that rigorously answers:

> _"At what % of sparsity does quality actually drop, and how much compute do we save?"_

---

## üèó System Architecture (GCP Production)

The platform is deployed on **Google Cloud Platform (GCP)** using **GKE (Google Kubernetes Engine)**, leveraging modern cloud-native patterns for scalability and reproducibility.

### Core Components

1.  **Orchestration (GKE)**:
    - **Scale-to-Zero GPU Pools**: Leveraging **NVIDIA T4** (and L4 ready) accelerators that only provision when a job is active, eliminating idle costs.
    - **Isolated Job Runners**: Every experiment (Dense baseline, IMP Ticket, Random Re-init) runs as a dedicated Kubernetes Job.
2.  **Continuous Integration (CI/CD)**:
    - **GitHub Actions + OIDC**: Automated Docker builds pushed to **Artifact Registry** using Workload Identity Federation (no static keys).
    - **Manual CD Dispatch**: Precision control over GPU training jobs directly from the GitHub Actions UI.
3.  **Artifact Store (GCS)**:
    - Centralized, immutable storage in **Google Cloud Storage** for metric logs, model checkpoints, and visual sample grids.
4.  **Bulletproof Identity (OIDC + WIF)**:
    - **Zero-Trust Pillars**: Uses Workload Identity Federation to eliminate static keys.
    - **Secure Attribution**: Enforces strict `--attribute-condition` policies to ensure only authorized repositories can act as the TicketSmith service account.
5.  **Report Generator**:
    - A CPU-only job that aggregates all run data into a single **Executive Summary**.
    - Outputs decision-ready plots (Quality vs. Sparsity) and "Serving Scorecards".
6.  **Hardware Parity**:
    - Universal container image ensures identical logic across CPU validation and GPU production phases.

---

## üî¨ Scientific Approach: Validating the Hypothesis

We implement **Iterative Magnitude Pruning (IMP)** to find winning "lottery tickets":

1.  **Dense Baseline**: Train a full model (Theta_0) to convergence.
2.  **Prune**: Remove the bottom $p\%$ of weights by magnitude (creating a Mask $M$).
3.  **Rewind**: Reset the remaining weights back to their original initial value (Theta_0).
4.  **Retrain**: Train the sparse network to convergence.
5.  **Quality Gate**: Automatically compare against the dense baseline using Loss Delta and Accuracy drops.
6.  **Benchmark**: Measure real wall-clock speedup (Latency/Throughput) on target hardware.

### üß™ Results: The "Winning Ticket" Verified

I validated the core LTH claims through three key outcomes:

- **Rewind beats Random**: Pruned models rewound to their original initialization consistently outperformed identical architectures with random initialization.
- **Performance Tracking**: Sparse subnetworks (up to 80% sparsity) tracked dense model accuracy within a <0.5% margin.
- **The Breaking Point**: Identified a clear "Safe Optimization Zone" (50-80% sparsity) before performance degradation occurs at >90%.

---

## üìä Performance Scorecard (Verified on NVIDIA T4)

| Variant            | Sparsity | Test Accuracy | Status  | Rel. Throughput |
| :----------------- | :------: | :-----------: | :-----: | :-------------: |
| **Dense Baseline** |    0%    |     99.1%     | ‚úÖ PASS |      1.0x       |
| **Winning Ticket** |   80%    |     98.9%     | ‚úÖ PASS |    **1.8x**     |
| **Random Re-init** |   80%    |     94.2%     | ‚ùå FAIL |      1.8x       |

_Measurements taken on NVIDIA T4 (GKE g2-standard-_) using the TicketSmith Benchmarking Suite.\*

---

## üß™ Proof of Concept: The MNIST Case Study

To validate the platform, I ran a full **Iterative Magnitude Pruning (IMP)** suite on a standard CNN architecture. The goal was to find a "Winning Ticket" that could match the accuracy of a full dense model while being significantly smaller.

### üìà The Data (Verified Baseline vs Outcome)

| Metric         | **Baseline (Dense)** | **Winning Ticket (Outcome)** | **Result**                      |
| :------------- | :------------------- | :--------------------------- | :------------------------------ |
| **Accuracy**   | 98.94%               | **98.98%**                   | **Quality Maintained** (+0.04%) |
| **Weights**    | 100% (Full)          | **51.2% (Sparse)**           | **48.8% Optimization**          |
| **Parameters** | ~1.2M                | **~0.6M**                    | **Significant Memory Win**      |

### üí° The Achievement

We removed **nearly half (48.8%)** of the model's weights and the resulting sparse model actually **outperformed** the full dense baseline. This confirms the **Lottery Ticket Hypothesis**: a much smaller subnetwork existed within the original initialization that was capable of learning the task just as effectively as the large network.

---

## üõ† Engineering Evolution: Azure to GCP Migration

TicketSmith's history demonstrates **architectural robustness under constraints**.

1.  **Azure Phase (CPU Validation)**: Initial deployment on AKS encountered regional GPU quota limits. I pivoted to an intentional CPU-only validation phase to prove the container, logic, and artifact pipeline worked end-to-end.
2.  **Migration Phase**: Documented and executed a full migration from Azure (AKS/Blob/ACR) to GCP (GKE/GCS/GAR).
3.  **Production Phase (Current)**: Fully operational GPU training with scale-to-zero autoscaling and CI/CD automation. Now conducting high-fidelity experiments on **CIFAR-10** using **ResNet-18** architectures to validate LTH at scale.

## üõ°Ô∏è The Engineering Struggle: Hard-won Lessons

Building a cross-cloud ML platform isn't just about architectural diagrams‚Äîit's about overcoming the friction of real-world infrastructure.

### 1. Windows Shell Parsing vs. Cloud CLI

One of the greatest points of friction was the **Windows Shell (PowerShell/CMD)** fighting against the complex multi-argument flags required by the Google Cloud SDK. Commas and quotes within strings (e.g., `--attribute-mapping="a=b,c=d"`) are often mangled by the underlying shell pre-processor.

- **Resolution**: Sidestepped shell parsing entirely by using JSON and YAML configuration files which `gcloud` reads directly via `--attribute-mapping-file` and `--flags-file`.

### 2. The Evolution of Zero-Trust (WIF Security)

GCP has recently tightened its **Workload Identity Federation (WIF)** requirements. While many legacy tutorials imply a simple mapping is enough, current GCP policies **REQUIRE** an `--attribute-condition` for OIDC providers. Without this, the IAM bridge remains closed with a cryptic `INVALID_ARGUMENT` error.

- **Lesson**: Security by default is the new frontier. Explicitly white-listing the repo owner/path in the identity provider is no longer optional‚Äîit is a production requirement.

### 3. Identity Resolution (Project Number vs. ID)

Global IAM bindings in GCP often silently require the **12-digit Project Number** instead of the human-readable Project ID in certain formatted strings (like `principalSet://`).

- **Lesson**: Always verify identity strings against the raw project metadata when automated bindings fail.

---

## üö¶ Local Quickstart

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Run a full iterative pruning experiment
python -m ticketsmith.prune --config configs/imp_mnist.yaml

# 3. Generate the Executive Report
python -m ticketsmith.report --runs-prefix runs
```

### Key Scripts

- `ticketsmith.train`: Runs standard dense training.
- `ticketsmith.prune`: Executes the Lottery Ticket IMP loop.
- `ticketsmith.benchmark_cli`: Standalone inference benchmarks.
- `.github/workflows/`: Production CI/CD definitions.
